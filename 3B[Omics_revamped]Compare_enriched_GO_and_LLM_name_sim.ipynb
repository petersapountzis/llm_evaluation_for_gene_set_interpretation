{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "import numpy as np"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the similarity between LLM and the enriched GO names (any GO term that is significant)\n",
    "\n",
    "1. Remove the 'regulation of' from the name and run semantic similarity between GO and LLM names\n",
    "2. pick the highest semantic similarity GO term \n",
    "3. plot the llm JI vs GO JI plot with colored by semantic similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "input_file = 'data/omics_revamped_LLM_gprofiler_new_gene_name_DF.tsv'\n",
    "input_df = pd.read_csv(input_file, sep='\\t')\n",
    "\n",
    "# find cases where there is regulation of\n",
    "example_df = input_df.loc[(input_df['Term'].str.contains('regulation of', flags=re.IGNORECASE, regex=True))&(input_df['LLM Name'].str.contains('regulation of', flags=re.IGNORECASE, regex=True))]\n",
    "print(example_df.shape)\n",
    "example_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "import re\n",
    "def remove_regulation_of(text):\n",
    "    text = text.lower()\n",
    "    # Define the regular expression pattern\n",
    "    pattern = r'.*regulation of '\n",
    "    # # find if match \n",
    "    # match = re.match(pattern, text)\n",
    "    # Substitute the matched pattern with an empty string\n",
    "    result = re.sub(pattern, '', text)\n",
    "    return result\n",
    "\n",
    "\n",
    "def iter_df_trim_name(row):\n",
    "    trim_GO_term = remove_regulation_of(row['Term'])\n",
    "    \n",
    "    llm_name = row['LLM Name'].split('and')\n",
    "    if len(llm_name) > 1:\n",
    "        split_name = []\n",
    "        for name in llm_name:\n",
    "            trim_llm_name = remove_regulation_of(name)\n",
    "            split_name.append(trim_llm_name)\n",
    "        return ' and '.join(split_name), trim_GO_term\n",
    "    else:\n",
    "        trim_llm_name = remove_regulation_of(row['LLM Name'])\n",
    "    # trim_llm_name = remove_regulation_of(row['LLM Name'])\n",
    "   \n",
    "    return trim_llm_name, trim_GO_term\n",
    "# Example usage\n",
    "# example_string = \"This is a test string with Regulation of Gene Expression\"\n",
    "# cleaned_string = remove_regulation_of(example_string)\n",
    "# print(cleaned_string)  # Output: \"gene expression\"\n",
    "\n",
    "# Apply the function to the 'Term' column\n",
    "example_df[['trimed LLM Name','trimed Term']] = input_df.apply(lambda row: iter_df_trim_name(row), axis=1, result_type='expand')\n",
    "example_df [['LLM Name', 'Term','trimed LLM Name','trimed Term']].sample(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "# run on the input \n",
    "input_df[['trimed LLM Name','trimed Term']] = input_df.apply(lambda row: iter_df_trim_name(row), axis=1, result_type='expand')\n",
    "input_df.to_csv('data/omics_revamped_LLM_gprofiler_new_gene_name_DF_trimed_name.tsv', sep='\\t', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "from semanticSimFunctions import getNameSimilarities_no_repeat\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "SapBERT_tokenizer = AutoTokenizer.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n",
    "SapBERT_model = AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n",
    "\n",
    "## test run with 10 examples\n",
    "\n",
    "new_sim_df, llm_emb_dict, go_emb_dict = getNameSimilarities_no_repeat(example_sim_df, 'trimed LLM Name', 'trimed Term',SapBERT_tokenizer, SapBERT_model, llm_name_embedding_dict = {},go_term_embedding_dict = {}, simMetric = 'cosine_similarity', epsilon= 0.05)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run semantic similarity in the command line (using the same environment) \n",
    "\n",
    "python run_omics_sem_sim.py --inputFile data/omics_revamped_LLM_gprofiler_new_gene_name_DF_trimed_name.tsv --nameCol1 'trimed LLM Name' --nameCol2 'trimed Term'\n",
    "\n",
    "\n",
    "Note:\n",
    "- will save the embeddings for all LLM names and GO term name as separate files \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find the highest semantic similar GO among the ones that are significant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "sim_val_file = 'data/omics_revamped_LLM_gprofiler_new_gene_name_DF_trimed_name_simVals_DF.tsv'\n",
    "sim_val_df = pd.read_csv(sim_val_file, sep='\\t')\n",
    "print(sim_val_df.shape)\n",
    "sim_val_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "adj_pval_thresh = 0.05\n",
    "llm_confidence_thresh = 0.1\n",
    "\n",
    "llm_conf_field = 'Score'\n",
    "go_pval_field = 'Adjusted P-value'\n",
    "\n",
    "both_named = sim_val_df[(sim_val_df[llm_conf_field] >= llm_confidence_thresh)&(sim_val_df[go_pval_field] <= adj_pval_thresh)]\n",
    "\n",
    "print(both_named.shape)\n",
    "print(both_named['GeneSetID'].nunique())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "from utils.analyze_enrichment_utils import cal_JI_coverage\n",
    "def get_max_semantic_sim(df):\n",
    "    return df.loc[df['LLM_name_GO_term_sim'].idxmax()]\n",
    "group_col = [\"Source\", \"GeneSetID\", \"GeneSetName\", \"GeneList\"] # group by these columns in future steps\n",
    "grouped_df = both_named.groupby(group_col)\n",
    "\n",
    "max_semantic_sim_df = grouped_df.apply(get_max_semantic_sim).reset_index(drop = True)\n",
    "\n",
    "max_semantic_sim_df  = cal_JI_coverage(max_semantic_sim_df)\n",
    "\n",
    "# merge the LLM supporting genes and JI \n",
    "\n",
    "max_semantic_sim_df[[ 'n_Genes', 'GeneList', 'LLM Name', 'Term','Adjusted P-value', 'intersection_size', 'term_size', 'trimed LLM Name', 'trimed Term',\n",
    "       'LLM_name_GO_term_sim', 'gprofiler_JI']].head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "## load the LLM coverage and JI data as a common df to merge\n",
    "llm_coverage_df = pd.read_csv(\"data/omics_revamped_LLM_genecounts_DF.tsv\", sep=\"\\t\")\n",
    "\n",
    "llm_JI_file = 'data/omics_revamped_LLM_w_best_matching_GO_terms_for_JI.tsv'\n",
    "llm_ji_df = pd.read_csv(llm_JI_file, sep=\"\\t\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "# merge with the LLM coverage data\n",
    "merged_DF = pd.merge(max_semantic_sim_df, llm_coverage_df, on=['Source','GeneSetID','GeneSetName', 'GeneList', 'n_Genes'], how='left')\n",
    "print(merged_DF.shape)\n",
    "# print(merged_DF.columns)\n",
    "\n",
    "\n",
    "# merge with the LLM JI data\n",
    "\n",
    "merged_DF = pd.merge(merged_DF, llm_ji_df, on=['Source','GeneSetID','GeneList','n_Genes', 'LLM Name','Supporting Count'], how='left')\n",
    "print(merged_DF.shape)\n",
    "print(merged_DF.columns)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the JI correlation scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams.update({'font.size': 7, 'font.family': 'sans-serif'})\n",
    "plt.rcParams['xtick.labelsize'] = 7\n",
    "plt.rcParams['ytick.labelsize'] = 7\n",
    "plt.rcParams['axes.labelsize'] = 7\n",
    "plt.rcParams['axes.titlesize'] = 7"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "similarity_thre = 0.5\n",
    "\n",
    "# y_field = 'gprofiler_JI'\n",
    "# y_label = 'g:Profiler coverage'\n",
    "# x_field = 'LLM_JI'\n",
    "# x_label = 'GPT-4 coverage'\n",
    "\n",
    "y_field = 'intersection_size'\n",
    "y_label = 'Number of covered genes\\n(g:Profiler)'\n",
    "x_field = 'Supporting Count'\n",
    "x_label = 'Number of covered genes\\n(GPT-4)'\n",
    "\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_data_high = merged_DF[merged_DF['LLM_name_GO_term_sim'] >= similarity_thre]\n",
    "filtered_data_low = merged_DF[merged_DF['LLM_name_GO_term_sim'] < similarity_thre]\n",
    "print(f'high similarity: {filtered_data_high.shape[0]}', f'\\nin percentage: {filtered_data_high.shape[0]/merged_DF.shape[0] *100 :.2f}%')\n",
    "print(f'low similarity: {filtered_data_low.shape[0]}', f'\\nin percentage: {filtered_data_low.shape[0]/merged_DF.shape[0] *100 :.2f}%')\n",
    "\n",
    "# further breakdown the high similarity group into high and low JI\n",
    "filtered_data_high_JI_high = filtered_data_high[filtered_data_high[x_field]>filtered_data_high[y_field]]\n",
    "print(f'high similarity high number genes: {filtered_data_high_JI_high.shape[0]}', f'\\nin percentage: {filtered_data_high_JI_high.shape[0]/merged_DF.shape[0] *100 :.2f}%')\n",
    "filtered_data_high_JI_low = filtered_data_high[filtered_data_high[x_field]<=filtered_data_high[y_field]]\n",
    "# LLM JI vs gprofiler JI, colored by the similarity with countinuous color\n",
    "plt.figure(figsize=(3,3))\n",
    "\n",
    "# Create the scatter plot using the filtered data with explicit normalization\n",
    "# Here, we switch to using matplotlib directly\n",
    "\n",
    "plt.scatter(\n",
    "    x=filtered_data_high[x_field], \n",
    "    y=filtered_data_high[y_field], \n",
    "    c='#ae2012',\n",
    "    s=8,  # Set the size of the points\n",
    "    label='High similarity'\n",
    ")\n",
    "\n",
    "# plot the low similarity data\n",
    "plt.scatter(\n",
    "    x=filtered_data_low[x_field], \n",
    "    y=filtered_data_low[y_field], \n",
    "    c='#294c60',\n",
    "    s=8,  # Set the size of the points\n",
    "    label='Low similarity'\n",
    ")\n",
    "\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "# plt.axvline(x=JI_thresh, color='black', linestyle='--', label='JI threshold')\n",
    "# plt.axhline(y=JI_thresh, color='black', linestyle='--')\n",
    "plt.xlim(-0.05, 40)\n",
    "plt.ylim(-0.05, 40)\n",
    "# Ensure the x and y ticks are the same\n",
    "ticks = range(0, 41, 10)\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks)\n",
    "# plot diagonal line\n",
    "plt.plot([0, 40], [0, 40], lw=1, color = 'black', linestyle='--')\n",
    "\n",
    "\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.savefig('figures/omics_LLM_genes_vs_gprofiler_genes_sep_similarity.svg', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "source": [
    "def clean_gene_list(row):\n",
    "    gene_list = row['intersections'].split(',')\n",
    "    return ' '.join(gene_list)\n",
    "\n",
    "merged_DF['intersections'] = merged_DF.apply(lambda row: clean_gene_list(row), axis=1)\n",
    "merged_DF.to_csv('data/omics_revamped_LLM_gprofiler_new_gene_name_DF_trimed_name_simVals_max_named.tsv', sep='\\t', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
