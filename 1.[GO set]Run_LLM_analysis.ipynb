{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query GPT-4 for name and analysis using a toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:16<02:24, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:36<02:27, 18.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:55<02:13, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:11<01:46, 17.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:39<01:46, 21.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:56<01:19, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:11<00:54, 18.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:35<00:40, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:53<00:19, 19.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:09<00:00, 18.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "from utils.openai_query import openai_chat\n",
    "from utils.prompt_factory import make_user_prompt\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "## check example_config.json for the format of the config file\n",
    "with open('./jsonFiles/GOLLMrun_config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "context = config['CONTEXT']\n",
    "gpt_model = config['GPT_MODEL']\n",
    "temperature = config['TEMP']\n",
    "max_tokens = config['MAX_TOKENS']\n",
    "rate_per_token = config['RATE_PER_TOKEN']\n",
    "LOG_FILE = config['LOG_NAME'] + '_log.json'\n",
    "DOLLAR_LIMIT = config['DOLLAR_LIMIT']\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"] # set your openai api key in the environment variable or set in config\n",
    "# Generate list of genes from file (file: data/go_terms_sample.csv) check notebook 0.[Prep GO] Download_and_parse_GO.ipynb\n",
    "df = pd.read_csv('data/GO_term_analysis/toy_example.csv', sep = ',',index_col=0)\n",
    "\n",
    "df['LLM Name'] = None\n",
    "df['LLM Analysis'] = None\n",
    "# print(df.head())\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    term_genes = row['Genes']\n",
    "    genes = term_genes.split()\n",
    "    prompt = make_user_prompt(genes)\n",
    "    # print(prompt)\n",
    "    analysis = openai_chat(context, prompt, gpt_model,temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT)\n",
    "    \n",
    "    llm_name = analysis.split(\"\\n\")[0].replace(\"Process: \", \"\")\n",
    "    df.loc[i, 'LLM Name'] = llm_name\n",
    "    \n",
    "    llm_analysis = analysis.split('\\n', 2)[2]\n",
    "    df.loc[i, 'LLM Analysis'] = llm_analysis\n",
    "    # go_name = row['Term_Description'].lower()\n",
    "    # print(go_name)\n",
    "\n",
    "df.to_csv('data/GO_term_analysis/LLM_processed_toy_example.tsv', index=True, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the script for batch run\n",
    "\n",
    "input_file = 'data/GO_term_analysis/toy_example.csv'\n",
    "config = './jsonFiles/GOLLMrun_config.json'\n",
    "%run query_llm_for_analysis.py --input $input_file --start 0 --end 1 --config $config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkout and combine the output from the batch run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(50, 6)\n",
      "(1000, 6)\n",
      "Any duplicated GO:  0\n",
      "Any NAs in the LLM res:  0\n",
      "Any duplicated LLM analysis:  0\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "### sanity check code along the way\n",
    "processed_files = glob('data/GO_term_analysis/LLM_processed_selected_go_terms*.tsv')\n",
    "\n",
    "for file in processed_files:\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    df.set_index('GO', inplace=True)\n",
    "    ranges = file.split('/')[-1].split('.')[0].split('_')[5:7]\n",
    "    with open(f'data/GO_term_analysis/LLM_response_go_terms_{ranges[0]}_{ranges[1]}.json') as fp:\n",
    "        llm_response_dict = json.load(fp)\n",
    "    for go_term, row in df.iterrows():\n",
    "        if llm_response_dict[go_term] == 'NO ANALYSIS':\n",
    "            print(file.split('/')[-1])\n",
    "            print(f'No analysis for {go_term}')\n",
    "            continue\n",
    "        else:\n",
    "            llm_analysis = llm_response_dict[go_term].split('\\n', 2)[2]\n",
    "            if df.loc[go_term, 'LLM Analysis'] != llm_analysis:\n",
    "                print(f'LLM analysis for {go_term} is different')\n",
    "            \n",
    "    df.reset_index(inplace=True)\n",
    "#     # print(ranges)\n",
    "    print(df.shape)\n",
    "\n",
    "    \n",
    "combined_df = pd.concat([pd.read_csv(f, sep = '\\t') for f in processed_files])\n",
    "print(combined_df.shape)\n",
    "print('Any duplicated GO: ',combined_df['GO'].duplicated().sum())\n",
    "print('Any NAs in the LLM res: ', combined_df['LLM Name'].isna().sum())\n",
    "print('Any duplicated LLM analysis: ', combined_df['LLM Analysis'].duplicated(keep=False).sum())\n",
    "\n",
    "combined_df.to_csv('data/GO_term_analysis/LLM_processed_selected_1000_go_terms.tsv', index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
