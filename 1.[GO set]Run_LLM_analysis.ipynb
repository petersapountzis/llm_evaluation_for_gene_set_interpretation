{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query GPT-4 for name and analysis using a toy example\n",
    "\n",
    "#### The new prompt includes a query for confidence score and an example analysis to help the LLM in its task.\n",
    "\n",
    "#### The LLM Score has its own column in the output TSV file.\n",
    "\n",
    "#### The JSON config file is updated to use \"GPT-4_1106-preview\" build."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T03:03:21.282769Z",
     "start_time": "2025-02-20T02:59:35.231973Z"
    }
   },
   "source": [
    "# run in the command line  \n",
    "input_file = 'data/GO_term_analysis/1000_selected_go_terms.csv'\n",
    "config = './jsonFiles/toyexample.json'\n",
    "set_index = 'GO'\n",
    "gene_column = 'Genes'\n",
    "gene_sep = ' '\n",
    "start = 0\n",
    "end = 10   \n",
    "out_file = 'data/GO_term_analysis/10_go_term_test.tsv'\n",
    "\n",
    "%run query_llm_for_analysis.py --config $config \\\n",
    "            --initialize \\\n",
    "            --input $input_file \\\n",
    "            --input_sep  ','\\\n",
    "            --set_index $set_index \\\n",
    "            --gene_column $gene_column\\\n",
    "            --gene_sep ' ' \\\n",
    "            --start $start \\\n",
    "            --end $end \\\n",
    "            --output_file $out_file"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petersapountzis/Desktop/tulaneCBG/EnrichGPT/llm_evaluation_for_gene_set_interpretation/query_llm_for_analysis.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{column_prefix} Name'] = None\n",
      "/Users/petersapountzis/Desktop/tulaneCBG/EnrichGPT/llm_evaluation_for_gene_set_interpretation/query_llm_for_analysis.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{column_prefix} Analysis'] = None\n",
      "/Users/petersapountzis/Desktop/tulaneCBG/EnrichGPT/llm_evaluation_for_gene_set_interpretation/query_llm_for_analysis.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{column_prefix} Score'] = -np.inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Genes', 'Gene_Count', 'Term_Description'], dtype='object')\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:14<02:10, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1390\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:35<02:27, 18.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1892\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:03<02:38, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1837\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:17<01:55, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:43<01:48, 21.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:06<01:29, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1614\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:39<01:16, 25.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:57<00:46, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1633\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:24<00:24, 24.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2221\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petersapountzis/Desktop/tulaneCBG/EnrichGPT/llm_evaluation_for_gene_set_interpretation/query_llm_for_analysis.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{column_prefix} Score bins'] = pd.cut(df[f'{column_prefix} Score'], bins=bins, labels=labels)\n",
      "100%|██████████| 10/10 [03:46<00:00, 22.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566\n",
      "Saved progress for 10 genesets\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/petersapountzis/Desktop/tulaneCBG/EnrichGPT/llm_evaluation_for_gene_set_interpretation/query_llm_for_analysis.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{column_prefix} Score bins'] = pd.cut(df[f'{column_prefix} Score'], bins=bins, labels=labels)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run in Jupyter Notebook "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T02:24:17.577990Z",
     "start_time": "2025-02-20T02:24:13.325564Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "from utils.openai_query import openai_chat\n",
    "from utils.prompt_factory import make_user_prompt_with_score\n",
    "from utils.server_model_query import server_model_chat\n",
    "from utils.llm_analysis_utils import process_analysis, save_progress\n",
    "from utils.genai_query import query_genai_model\n",
    "from tqdm import tqdm\n",
    "import constant\n",
    "import openai\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "import time as time\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai QUERY being run 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\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default run is using GPT4**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T02:24:20.484982Z",
     "start_time": "2025-02-20T02:24:20.468550Z"
    }
   },
   "source": [
    "## load variables\n",
    "initialize = True # if True, then initialize the input table with llm names, analysis and score to None \n",
    "# Replace with your actual values\n",
    "input_file = 'data/GO_term_analysis/1000_selected_go_terms.csv'\n",
    "config_file = './jsonFiles/peter_config.json'\n",
    "set_index = 'GO'\n",
    "gene_column = 'Genes'\n",
    "gene_sep = ','\n",
    "start = 0\n",
    "end = 5   \n",
    "out_file = 'data/GO_term_analysis/peter_test_v2'\n",
    "customized_prompt = False # if True, then the prompt will be the custom prompt, if False, then the prompt will use default\n",
    "\n",
    "# load the config file\n",
    "with open(config_file) as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "if customized_prompt:\n",
    "    # make sure the file exist \n",
    "    if os.path.isfile(config['CUSTOM_PROMPT_FILE']):\n",
    "        with open(config['CUSTOM_PROMPT_FILE'], 'r') as f: # replace with your actual customized prompt file\n",
    "            customized_prompt = f.read()\n",
    "            assert len(customized_prompt) > 1, \"Customized prompt is empty\"\n",
    "    else:\n",
    "        print(\"Customized prompt file does not exist\")\n",
    "        customized_prompt = None\n",
    "else:\n",
    "    customized_prompt = None\n",
    "\n",
    "# Load OpenAI key, context, and model used \n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "context = config['CONTEXT']\n",
    "model = config['MODEL']\n",
    "temperature = config['TEMP']\n",
    "max_tokens = config['MAX_TOKENS']\n",
    "if model.startswith('gpt'):\n",
    "    rate_per_token = config['RATE_PER_TOKEN']\n",
    "    DOLLAR_LIMIT = config['DOLLAR_LIMIT']\n",
    "LOG_FILE = config['LOG_NAME']+'_log.json'\n",
    "\n",
    "SEED = constant.SEED\n",
    "column_prefix = model.split('-')[0]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T02:24:21.521629Z",
     "start_time": "2025-02-20T02:24:21.501008Z"
    }
   },
   "source": [
    "import openai\n",
    "\n",
    "# handle the logger so it create a new one for each model run\n",
    "def get_logger(filename):\n",
    "    logger = logging.getLogger(filename)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if not logger.handlers:\n",
    "        file_handler = logging.FileHandler(filename)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def main(df):\n",
    "    analysis_dict  = {}\n",
    "    error_message = \"unknown error\"\n",
    "\n",
    "    logger = get_logger(f'{out_file}.log')\n",
    "\n",
    "    i = 0 #used for track progress and saving the file\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        #only process None rows \n",
    "        if pd.notna(row[f'{column_prefix} Analysis']):\n",
    "            continue\n",
    "        \n",
    "        gene_data = row[gene_column]\n",
    "        # if gene_data is not a string, then skip\n",
    "        if type(gene_data) != str:\n",
    "            \n",
    "            logger.warning(f'Gene set {idx} is not a string, skipping')\n",
    "            continue\n",
    "        genes = gene_data.split(gene_sep)\n",
    "        \n",
    "        if len(genes) >1000:\n",
    "            logger.warning(f'Gene set {idx} is too big, skipping')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            prompt = make_user_prompt_with_score(genes)\n",
    "            # print(prompt)\n",
    "            finger_print = None\n",
    "            if model.startswith('gpt'):\n",
    "                print(\"Accessing OpenAI API\")\n",
    "                analysis, finger_print = openai_chat(context, prompt, model, temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT, SEED)\n",
    "            elif model.startswith('gemini'):\n",
    "                print(\"Using Google Gemini API\")\n",
    "                analysis, error_message = query_genai_model(f\"{context}\\n{prompt}\", model, temperature, max_tokens, LOG_FILE) \n",
    "            else:\n",
    "                print(\"Using server model\")\n",
    "                analysis, error_message= server_model_chat(context, prompt, model, temperature, max_tokens,LOG_FILE, SEED)\n",
    "\n",
    "            \n",
    "            if analysis:\n",
    "                # print(analysis)\n",
    "                llm_name, llm_score, llm_analysis = process_analysis(analysis)\n",
    "                # clean up the score and return float\n",
    "                try:\n",
    "                    llm_score_value =  float(re.sub(\"[^0-9.-]\", \"\", llm_score))\n",
    "                except ValueError:\n",
    "                    llm_score_value = llm_score\n",
    "            \n",
    "                \n",
    "                df.loc[idx, f'{column_prefix} Name'] = llm_name\n",
    "                df.loc[idx, f'{column_prefix} Analysis'] = llm_analysis\n",
    "                df.loc[idx, f'{column_prefix} Score'] = llm_score_value\n",
    "                analysis_dict[f'{idx}_{column_prefix}'] = analysis\n",
    "                # Log success with fingerprint\n",
    "                logger.info(f'Success for {idx} {column_prefix}.')\n",
    "                if finger_print:\n",
    "                    logger.info(f'GPT_Fingerprint for {idx}: {finger_print}')\n",
    "                    \n",
    "            else:\n",
    "                logger.error(f'Error for query gene set {idx}: {error_message}')\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error for {idx}: {e}')\n",
    "            continue\n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            save_progress(df, analysis_dict, out_file)\n",
    "            # df.to_csv(f'{out_file}.tsv', sep='\\t', index=True)\n",
    "            print(f\"Saved progress for {i} genesets\")\n",
    "    # save the final file\n",
    "    save_progress(df, analysis_dict, out_file)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-20T02:24:22.288550Z"
    }
   },
   "source": [
    "#Define your own loop for running the pipeline\n",
    "## 12-18-2023: this loop is for run the default gene set and the contaminated gene sets \n",
    "## can modify this loop for different models or only run on default gene set\n",
    "\n",
    "##12-27-23: edited the prompt \n",
    "if __name__ == \"__main__\":\n",
    "    import openai\n",
    "    \n",
    "    df = pd.read_csv(input_file, sep=',', index_col=set_index)\n",
    "    \n",
    "    if 'gpt' in model:\n",
    "        name_fix = '_'.join(model.split('-')[:2])\n",
    "    else:\n",
    "        name_fix = model.replace(':', '_')\n",
    "    column_prefix = name_fix + '_default'\n",
    "    print(column_prefix)\n",
    "    \n",
    "    if initialize:\n",
    "        # initialize the input file with llm names, analysis and score to None\n",
    "        df[f'{column_prefix} Name'] = None\n",
    "        df[f'{column_prefix} Analysis'] = None\n",
    "        df[f'{column_prefix} Score'] = None\n",
    "    main(df)  ## run with the real set \n",
    "    \n",
    "    ## run the pipeline for contaiminated gene sets \n",
    "    contaminated_columns = [col for col in df.columns if col.endswith('contaminated_Genes')]\n",
    "    # print(contaminated_columns)\n",
    "    for col in contaminated_columns:\n",
    "        gene_column = col ## Note need to change the gene_column to the contaminated column\n",
    "        contam_prefix = '_'.join(col.split('_')[0:2])\n",
    "        \n",
    "        column_prefix = name_fix + '_' +contam_prefix\n",
    "        print(column_prefix)\n",
    "\n",
    "        if initialize:\n",
    "            # initialize the input file with llm names, analysis and score to None\n",
    "            df[f'{column_prefix} Name'] = None\n",
    "            df[f'{column_prefix} Analysis'] = None\n",
    "            df[f'{column_prefix} Score'] = None\n",
    "        main(df)\n",
    "    df.head()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_4_default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:13<3:43:10, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1335\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:52<7:56:29, 28.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1826\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [01:15<7:10:21, 25.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [01:28<5:45:28, 20.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [01:46<5:28:24, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [02:00<4:54:04, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [02:23<5:23:45, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [02:38<5:01:19, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1434\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [03:02<5:29:33, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2054\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [03:22<5:26:45, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n",
      "Saved progress for 10 genesets\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [03:41<5:22:41, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [03:51<4:35:31, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1337\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [04:07<4:33:35, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1574\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14/1000 [04:29<5:00:31, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1849\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/1000 [04:49<5:05:32, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [05:16<5:50:18, 21.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/1000 [05:32<5:23:25, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1000 [05:51<5:16:38, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1577\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [06:06<4:54:45, 18.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1609\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1000 [06:25<5:02:27, 18.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667\n",
      "Saved progress for 20 genesets\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [06:42<4:50:09, 17.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [06:57<4:39:31, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1540\n",
      "Accessing OpenAI API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [07:00<5:11:25, 19.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 23\u001B[0m\n\u001B[1;32m     21\u001B[0m     df[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolumn_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Analysis\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     22\u001B[0m     df[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolumn_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Score\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m## run with the real set \u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m## run the pipeline for contaiminated gene sets \u001B[39;00m\n\u001B[1;32m     26\u001B[0m contaminated_columns \u001B[38;5;241m=\u001B[39m [col \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;28;01mif\u001B[39;00m col\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontaminated_Genes\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n",
      "Cell \u001B[0;32mIn[3], line 45\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpt\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccessing OpenAI API\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 45\u001B[0m     analysis, finger_print \u001B[38;5;241m=\u001B[39m \u001B[43mopenai_chat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrate_per_token\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLOG_FILE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDOLLAR_LIMIT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSEED\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgemini\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing Google Gemini API\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/tulaneCBG/EnrichGPT/llm_evaluation_for_gene_set_interpretation/utils/openai_query.py:44\u001B[0m, in \u001B[0;36mopenai_chat\u001B[0;34m(context, prompt, model, temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT, seed)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 44\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msystem\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemperature\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m     end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \n\u001B[1;32m     53\u001B[0m     \u001B[38;5;66;03m# print(response)\u001B[39;00m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;66;03m# tokens_used = response[\"usage\"][\"total_tokens\"]\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 279\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/openai/resources/chat/completions.py:863\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    860\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    861\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m    862\u001B[0m     validate_response_format(response_format)\n\u001B[0;32m--> 863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    873\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_completion_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodalities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreasoning_effort\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    898\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    899\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    901\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    903\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/openai/_base_client.py:1283\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1271\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1278\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1279\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1280\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1281\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1282\u001B[0m     )\n\u001B[0;32m-> 1283\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/openai/_base_client.py:960\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    958\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 960\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    961\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    962\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    963\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    964\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    965\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/openai/_base_client.py:996\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m    993\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSending HTTP Request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, request\u001B[38;5;241m.\u001B[39mmethod, request\u001B[38;5;241m.\u001B[39murl)\n\u001B[1;32m    995\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 996\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    997\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    998\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_should_stream_response_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    999\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1001\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m   1002\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered httpx.TimeoutException\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpx/_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[0;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[1;32m    910\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_timeout(request)\n\u001B[1;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[0;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    921\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpx/_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[0;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[1;32m    939\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[1;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    948\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpx/_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[0;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    977\u001B[0m     hook(request)\n\u001B[0;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    981\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpx/_client.py:1014\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m   1009\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1010\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1011\u001B[0m     )\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[0;32m-> 1014\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1016\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[1;32m   1018\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    237\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[1;32m    238\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[1;32m    239\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    247\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[1;32m    248\u001B[0m )\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[0;32m--> 250\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[1;32m    255\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mstatus,\n\u001B[1;32m    256\u001B[0m     headers\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m    257\u001B[0m     stream\u001B[38;5;241m=\u001B[39mResponseStream(resp\u001B[38;5;241m.\u001B[39mstream),\n\u001B[1;32m    258\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[1;32m    259\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    253\u001B[0m         closing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_requests_to_connections()\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_connections(closing)\n\u001B[0;32m--> 256\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    232\u001B[0m connection \u001B[38;5;241m=\u001B[39m pool_request\u001B[38;5;241m.\u001B[39mwait_for_connection(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[0;32m--> 236\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[1;32m    242\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[1;32m    244\u001B[0m     pool_request\u001B[38;5;241m.\u001B[39mclear_connection()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_closed\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[1;32m    135\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_closed()\n\u001B[0;32m--> 136\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs\n\u001B[1;32m     99\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[1;32m    100\u001B[0m     (\n\u001B[1;32m    101\u001B[0m         http_version,\n\u001B[1;32m    102\u001B[0m         status,\n\u001B[1;32m    103\u001B[0m         reason_phrase,\n\u001B[1;32m    104\u001B[0m         headers,\n\u001B[1;32m    105\u001B[0m         trailing_data,\n\u001B[0;32m--> 106\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    108\u001B[0m         http_version,\n\u001B[1;32m    109\u001B[0m         status,\n\u001B[1;32m    110\u001B[0m         reason_phrase,\n\u001B[1;32m    111\u001B[0m         headers,\n\u001B[1;32m    112\u001B[0m     )\n\u001B[1;32m    114\u001B[0m network_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_stream\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_headers\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    174\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 177\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mResponse):\n\u001B[1;32m    179\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    214\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[0;32m--> 217\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_network_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[0;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[0;32m--> 128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/ssl.py:1295\u001B[0m, in \u001B[0;36mSSLSocket.recv\u001B[0;34m(self, buflen, flags)\u001B[0m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1292\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1293\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1294\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1295\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuflen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1296\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1297\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv(buflen, flags)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/ssl.py:1168\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1166\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[1;32m   1167\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1168\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1169\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SSLError \u001B[38;5;28;01mas\u001B[39;00m x:\n\u001B[1;32m   1170\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m SSL_ERROR_EOF \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuppress_ragged_eofs:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T18:01:04.980140Z",
     "start_time": "2025-02-07T18:01:04.943279Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(input_file, sep\u001B[38;5;241m=\u001B[39minput_sep, index_col\u001B[38;5;241m=\u001B[39mset_index)\n\u001B[1;32m      2\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGO:2000136\u001B[39m\u001B[38;5;124m'\u001B[39m, :]\n\u001B[1;32m      4\u001B[0m genes \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGenes\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file, sep=',', index_col=set_index)\n",
    "df = df.loc['GO:2000136', :]\n",
    "\n",
    "genes = df['Genes'].split(' ')\n",
    "print(make_user_prompt_with_score(genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create parameter file to run the 1000 terms in batch "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T02:31:36.701632Z",
     "start_time": "2025-02-20T02:31:36.629823Z"
    }
   },
   "source": [
    "import pandas as pd \n",
    "selected_go = pd.read_csv('data/GO_term_analysis/1000_selected_go_contaminated.csv')\n",
    "# print(selected_go.head(2))\n",
    "\n",
    "# create a new dataframe by removing the 100 sets have been already ran \n",
    "model_compare_df = pd.read_csv('data/GO_term_analysis/model_compare/LLM_processed_model_compare_100set_gpt_4.tsv', sep='\\t', index_col='GO')\n",
    "model_compare_GO = model_compare_df.index.tolist()\n",
    "print(len(model_compare_GO))\n",
    "\n",
    "new = selected_go[~selected_go['GO'].isin(model_compare_GO)]\n",
    "print(new.shape)\n",
    "new.to_csv('data/GO_term_analysis/900_selected_go_contaminated.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(900, 6)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T02:31:39.477023Z",
     "start_time": "2025-02-20T02:31:39.460533Z"
    }
   },
   "source": [
    "## set up parameters for running gpt4 pipeline for the 1000 gene sets\n",
    "import os \n",
    "from glob import glob\n",
    "# Define start, step, and end values\n",
    "start = 0\n",
    "step = 50\n",
    "end = 900 #already ran 100 before\n",
    "\n",
    "# Create a range list\n",
    "range_list = list(range(start, end + step, step))\n",
    "\n",
    "# Create tuples for each consecutive pair in the list\n",
    "tuple_list = [(range_list[i], range_list[i+1]) for i in range(len(range_list)-1)]\n",
    "\n",
    "\n",
    "initialize = True \n",
    "input_file = './data/GO_term_analysis/900_selected_go_contaminated.csv'\n",
    "input_sep = constant.GO_FILE_SEP\n",
    "set_index = constant.GO_INDEX_COL  \n",
    "gene_column = constant.GO_GENE_COL \n",
    "gene_sep = ' '\n",
    "\n",
    "## create a param file \n",
    "conf_file = './jsonFiles/thousandGOrunGPT4_config.json'\n",
    "params = []\n",
    "for start, end in tuple_list:\n",
    "    out_file = f'./data/GO_term_analysis/LLM_processed_gpt_4_{start}_{end}'  \n",
    "    param = f\"--config {conf_file} \\\n",
    "        --initialize \\\n",
    "        --input {input_file} \\\n",
    "        --input_sep  '{input_sep}'\\\n",
    "        --set_index {set_index} \\\n",
    "        --gene_column {gene_column}\\\n",
    "        --gene_sep '{gene_sep}' \\\n",
    "        --start {start} \\\n",
    "        --end {end} \\\n",
    "        --output_file {out_file}\"\n",
    "    print(param)\n",
    "    params.append(param)\n",
    "print('number of params: ', len(params))\n",
    "\n",
    "with open('thousandGOsets_GPT4Run_params.txt', 'w') as f:\n",
    "    for p in params:\n",
    "        f.write(p+'\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 0         --end 50         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_0_50\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 50         --end 100         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_50_100\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 100         --end 150         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_100_150\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 150         --end 200         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_150_200\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 200         --end 250         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_200_250\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 250         --end 300         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_250_300\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 300         --end 350         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_300_350\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 350         --end 400         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_350_400\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 400         --end 450         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_400_450\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 450         --end 500         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_450_500\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 500         --end 550         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_500_550\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 550         --end 600         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_550_600\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 600         --end 650         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_600_650\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 650         --end 700         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_650_700\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 700         --end 750         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_700_750\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 750         --end 800         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_750_800\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 800         --end 850         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_800_850\n",
      "--config ./jsonFiles/thousandGOrunGPT4_config.json         --initialize         --input ./data/GO_term_analysis/900_selected_go_contaminated.csv         --input_sep  ','        --set_index GO         --gene_column Genes        --gene_sep ' '         --start 850         --end 900         --output_file ./data/GO_term_analysis/LLM_processed_gpt_4_850_900\n",
      "number of params:  18\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For CC and MF branch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T02:31:58.798110Z",
     "start_time": "2025-02-20T02:31:58.783154Z"
    }
   },
   "source": [
    "## set up parameters for running gpt4 pipeline for the 1000 gene sets for CC and MF\n",
    "import os \n",
    "from glob import glob\n",
    "# Define start, step, and end values\n",
    "start = 0\n",
    "step = 50\n",
    "end = 1000 \n",
    "\n",
    "\n",
    "# Create a range list\n",
    "range_list = list(range(start, end + step, step))\n",
    "\n",
    "# Create tuples for each consecutive pair in the list\n",
    "tuple_list = [(range_list[i], range_list[i+1]) for i in range(len(range_list)-1)]\n",
    "\n",
    "input_sep = constant.GO_FILE_SEP\n",
    "set_index = constant.GO_INDEX_COL  \n",
    "gene_column = constant.GO_GENE_COL \n",
    "gene_sep = ' '\n",
    "\n",
    "## create a param file \n",
    "conf_file = './jsonFiles/thousandGO_CC_MF_runGPT4_config.json'\n",
    "params = []\n",
    "for branch in ['CC', 'MF']:\n",
    "    input_file = f'./data/GO_term_analysis/CC_MF_branch/{branch}_1000_selected_go_terms.csv'\n",
    "    for start, end in tuple_list:\n",
    "        out_file = f'./data/GO_term_analysis/CC_MF_branch/LLM_processed_{branch}terms_gpt_4_{start}_{end}'  \n",
    "        param = f\"--config {conf_file} \\\n",
    "            --initialize \\\n",
    "            --input {input_file} \\\n",
    "            --input_sep  '{input_sep}'\\\n",
    "            --set_index {set_index} \\\n",
    "            --gene_column {gene_column}\\\n",
    "            --gene_sep '{gene_sep}' \\\n",
    "            --start {start} \\\n",
    "            --end {end} \\\n",
    "            --output_file {out_file}\"\n",
    "        print(param)\n",
    "        params.append(param)\n",
    "print('number of params: ', len(params))\n",
    "\n",
    "with open('thousandGOsets_CC_MF_GPT4Run_params.txt', 'w') as f:\n",
    "    for p in params:\n",
    "        f.write(p+'\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 0             --end 50             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_0_50\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 50             --end 100             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_50_100\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 100             --end 150             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_100_150\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 150             --end 200             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_150_200\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 200             --end 250             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_200_250\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 250             --end 300             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_250_300\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 300             --end 350             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_300_350\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 350             --end 400             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_350_400\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 400             --end 450             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_400_450\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 450             --end 500             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_450_500\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 500             --end 550             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_500_550\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 550             --end 600             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_550_600\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 600             --end 650             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_600_650\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 650             --end 700             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_650_700\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 700             --end 750             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_700_750\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 750             --end 800             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_750_800\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 800             --end 850             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_800_850\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 850             --end 900             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_850_900\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 900             --end 950             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_900_950\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/CC_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 950             --end 1000             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_CCterms_gpt_4_950_1000\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 0             --end 50             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_0_50\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 50             --end 100             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_50_100\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 100             --end 150             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_100_150\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 150             --end 200             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_150_200\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 200             --end 250             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_200_250\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 250             --end 300             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_250_300\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 300             --end 350             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_300_350\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 350             --end 400             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_350_400\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 400             --end 450             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_400_450\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 450             --end 500             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_450_500\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 500             --end 550             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_500_550\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 550             --end 600             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_550_600\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 600             --end 650             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_600_650\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 650             --end 700             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_650_700\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 700             --end 750             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_700_750\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 750             --end 800             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_750_800\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 800             --end 850             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_800_850\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 850             --end 900             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_850_900\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 900             --end 950             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_900_950\n",
      "--config ./jsonFiles/thousandGO_CC_MF_runGPT4_config.json             --initialize             --input ./data/GO_term_analysis/CC_MF_branch/MF_1000_selected_go_terms.csv             --input_sep  ','            --set_index GO             --gene_column Genes            --gene_sep ' '             --start 950             --end 1000             --output_file ./data/GO_term_analysis/CC_MF_branch/LLM_processed_MFterms_gpt_4_950_1000\n",
      "number of params:  40\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkout and combine the output from the batch run "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T02:43:15.009646Z",
     "start_time": "2025-02-20T02:43:14.959620Z"
    }
   },
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "### sanity check code along the way\n",
    "processed_files = glob('data/GO_term_analysis/LLM_processed_gpt_4*.tsv')\n",
    "\n",
    "for file in processed_files:\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    df.set_index('GO', inplace=True)\n",
    "    # check if the Analysis, Name and Score are all filled\n",
    "    columns = [col for col in df.columns if col.endswith('Analysis') or col.endswith('Name') or col.endswith('Score')]\n",
    "    print(columns)\n",
    "    for col in columns:\n",
    "        n_na = df[col].isna().sum()\n",
    "        if n_na > 0:\n",
    "            print(f'Error in {file} for {col}, has {n_na} NAs')\n",
    "            print(df[df[col].isna()])\n",
    "        else:\n",
    "            continue\n",
    "    # check if there is any duplicated GO terms\n",
    "    print('Any duplicated GO: ',df.index.duplicated().sum())\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "#     # print(ranges)\n",
    "    print(df.shape)\n",
    "\n",
    "    \n",
    "combined_df = pd.concat([pd.read_csv(f, sep = '\\t') for f in processed_files])\n",
    "print(combined_df.shape)\n",
    "print('Any duplicated GO: ',combined_df['GO'].duplicated().sum())\n",
    "analysis_columns = [col for col in combined_df.columns if col.endswith('Analysis')]\n",
    "print('Any duplicated LLM analysis: ', combined_df[analysis_columns[0]].duplicated(keep=False).sum())\n",
    "\n",
    "combined_df.to_csv('data/GO_term_analysis/LLM_processed_selected_1000_go_terms.tsv', index=False, sep='\\t')"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 29\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m#     # print(ranges)\u001B[39;00m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28mprint\u001B[39m(df\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 29\u001B[0m combined_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\t\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mprocessed_files\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(combined_df\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAny duplicated GO: \u001B[39m\u001B[38;5;124m'\u001B[39m,combined_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGO\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mduplicated()\u001B[38;5;241m.\u001B[39msum())\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/pandas/core/reshape/concat.py:368\u001B[0m, in \u001B[0;36mconcat\u001B[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;129m@deprecate_nonkeyword_arguments\u001B[39m(version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, allowed_args\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjs\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mconcat\u001B[39m(\n\u001B[1;32m    148\u001B[0m     objs: Iterable[NDFrame] \u001B[38;5;241m|\u001B[39m Mapping[HashableT, NDFrame],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    157\u001B[0m     copy: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    158\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m    159\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;124;03m    1   3   4\u001B[39;00m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 368\u001B[0m     op \u001B[38;5;241m=\u001B[39m \u001B[43m_Concatenator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    372\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjoin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    373\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    375\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    376\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverify_integrity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    378\u001B[0m \u001B[43m        \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    381\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/llm_eval/lib/python3.11/site-packages/pandas/core/reshape/concat.py:425\u001B[0m, in \u001B[0;36m_Concatenator.__init__\u001B[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[1;32m    422\u001B[0m     objs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(objs)\n\u001B[1;32m    424\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(objs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 425\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo objects to concatenate\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m keys \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    428\u001B[0m     objs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(com\u001B[38;5;241m.\u001B[39mnot_none(\u001B[38;5;241m*\u001B[39mobjs))\n",
      "\u001B[0;31mValueError\u001B[0m: No objects to concatenate"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine with the 100 sets that are already ran \n",
    "model_compare_df = pd.read_csv('data/GO_term_analysis/model_compare/LLM_processed_model_compare_100set_gpt_4.tsv', sep='\\t')\n",
    "common_cols = [col for col in model_compare_df.columns if col in combined_df.columns]\n",
    "print(common_cols)\n",
    "model_compare_df = model_compare_df.loc[:, common_cols]\n",
    "print(model_compare_df.shape)\n",
    "\n",
    "combined_df = pd.concat([combined_df, model_compare_df])\n",
    "print(combined_df.shape)\n",
    "print('Any duplicated GO: ',combined_df['GO'].duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df.to_csv('data/GO_term_analysis/LLM_processed_selected_1000_go_terms.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the cost and time usage \n",
    "import json \n",
    "from glob import glob\n",
    "\n",
    "logs = glob('./logs/thousand_GO_run_gpt4*.log')\n",
    "total_cost = 0\n",
    "total_run = 0\n",
    "time_total = 0\n",
    "for log in logs:\n",
    "    with open(log, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        total_cost += data['dollars_spent']\n",
    "        total_run += data['runs']\n",
    "        time_total += data['time_taken_total']\n",
    "print('total cost: {:.2f}'.format(total_cost))\n",
    "print('cost per run: {:.2f}'.format(total_cost/total_run))\n",
    "print('time per run: {:.2f}'.format(time_total/total_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the 1000 terms for MF and CC branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "### sanity check code along the way\n",
    "\n",
    "branches = ['CC', 'MF']\n",
    "for branch in branches:\n",
    "    branch_processed_files = glob(f'data/GO_term_analysis/CC_MF_branch/LLM_processed_{branch}terms_gpt_4*.tsv')\n",
    "    print(len(branch_processed_files))\n",
    "    for file in branch_processed_files:\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        df.set_index('GO', inplace=True)\n",
    "        # check if the Analysis, Name and Score are all filled\n",
    "        columns = [col for col in df.columns if col.endswith('Analysis') or col.endswith('Name') or col.endswith('Score')]\n",
    "        print(columns)\n",
    "        for col in columns:\n",
    "            n_na = df[col].isna().sum()\n",
    "            if n_na > 0:\n",
    "                print(f'Error in {file} for {col}, has {n_na} NAs')\n",
    "                print(df[df[col].isna()])\n",
    "            else:\n",
    "                continue\n",
    "        # check if there is any duplicated GO terms\n",
    "        if df.index.duplicated().sum() > 0:\n",
    "            print('Number of duplicated GO: ',df.index.duplicated().sum())\n",
    "        \n",
    "        df.reset_index(inplace=True)\n",
    "    #     # print(ranges)\n",
    "        print(df.shape)\n",
    "\n",
    "        \n",
    "    combined_df = pd.concat([pd.read_csv(f, sep = '\\t') for f in branch_processed_files])\n",
    "    print(combined_df.shape)\n",
    "    print(f'Any duplicated GO in {branch} combined file: ',combined_df['GO'].duplicated().sum())\n",
    "    analysis_columns = [col for col in combined_df.columns if col.endswith('Analysis')]\n",
    "    print(f'Any duplicated {branch} LLM analysis: ', combined_df[analysis_columns[0]].duplicated(keep=False).sum())\n",
    "\n",
    "    combined_df.to_csv(f'data/GO_term_analysis/CC_MF_branch/LLM_processed_selected_1000_go_{branch}terms.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
