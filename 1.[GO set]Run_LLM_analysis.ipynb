{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query GPT-4 for name and analysis using a toy example\n",
    "\n",
    "#### This uses an improved version of the original prompt that includes instructions to generate an LLM Confidence Score.\n",
    "\n",
    "#### The prompt also includes an example analysis to help the LLM in its task.\n",
    "\n",
    "#### The LLM Score has its own column in the output TSV file.\n",
    "\n",
    "#### The JSON config file is updated to use \"GPT-4_1106-preview\" build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "from utils.openai_query import openai_chat\n",
    "from utils.prompt_factory import make_user_prompt_with_score\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load variables\n",
    "# Replace with your actual values\n",
    "config_file = './jsonFiles/GOLLMrun_config.json'  # replace with your actual config file \n",
    "input_file = 'data/GO_term_analysis/toy_example.csv' # replace with your actual input file\n",
    "input_sep = ','  # replace with the separator\n",
    "set_index = 'GO'  # replace with your column name that you want to set as index or None\n",
    "gene_column = 'Genes'  # replace with your actual column name for the gene list\n",
    "gene_sep = ' '  # replace with your actual separator\n",
    "gene_features = None  # replace with your path to the gene features or None if you don't want to include in the prompt\n",
    "direct = False # if True, then the prompt will be a direct sentence asking for a name and analysis from the gene set, otherwise default or customized prompt\n",
    "out_file = 'data/GO_term_analysis/LLM_processed_toy_example_with_score'  # replace with your actual output file name\n",
    "customized_prompt = False # if True, then the prompt will be the custom prompt, if False, then the prompt will use default\n",
    "\n",
    "# load the config file\n",
    "with open(config_file) as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "if customized_prompt:\n",
    "    # make sure the file exist \n",
    "    if os.path.isfile(config['CUSTOM_PROMPT_FILE']):\n",
    "        with open(config['CUSTOM_PROMPT_FILE'], 'r') as f: # replace with your actual customized prompt file\n",
    "            customized_prompt = f.read()\n",
    "            assert len(customized_prompt) > 1, \"Customized prompt is empty\"\n",
    "    else:\n",
    "        print(\"Customized prompt file does not exist\")\n",
    "        customized_prompt = None\n",
    "else:\n",
    "    customized_prompt = None\n",
    "\n",
    "# Load OpenAI key, context, and model used \n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "context = config['CONTEXT']\n",
    "model = config['MODEL']\n",
    "temperature = config['TEMP']\n",
    "max_tokens = config['MAX_TOKENS']\n",
    "rate_per_token = config['RATE_PER_TOKEN']\n",
    "LOG_FILE = config['LOG_NAME']+'_log.json'\n",
    "DOLLAR_LIMIT = config['DOLLAR_LIMIT']\n",
    "\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:24<03:44, 24.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:00<04:10, 31.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:36<03:54, 33.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:21<03:46, 37.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:51<02:56, 35.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [03:14<02:03, 30.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [03:52<01:40, 33.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [04:16<01:00, 30.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [04:34<00:26, 26.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:53<00:00, 29.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file, sep = input_sep)\n",
    "df.set_index(set_index, inplace=True)\n",
    "\n",
    "df['LLM Name'] = None\n",
    "df['LLM Analysis'] = None\n",
    "df['LLM Score'] = None\n",
    "# print(df.head())\n",
    "\n",
    "llm_response_dict = {}\n",
    "i = 0 #used for track progress and saving the file\n",
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    term_genes = row['Genes']\n",
    "    genes = term_genes.split()\n",
    "    \n",
    "    if len(genes) >1000:\n",
    "        print(f'Gene set {i} has more than 1000 genes, skipping')\n",
    "        continue\n",
    "    try:\n",
    "        prompt = make_user_prompt_with_score(genes)\n",
    "        analysis, finger_print = openai_chat(context, prompt, model, temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT, SEED)\n",
    "    \n",
    "        if analysis:\n",
    "            llm_process = analysis.split(\"\\n\")[0].replace(\"Process: \", \"\")\n",
    "            llm_score = llm_process.split(\" \")[-1].strip(\"()\")\n",
    "            llm_name = llm_process.rsplit(\" \", 1)[0]\n",
    "            llm_analysis = analysis.split('\\n', 2)[2]\n",
    "            \n",
    "            \n",
    "            df.loc[idx, 'LLM Name'] = llm_name\n",
    "            df.loc[idx, 'LLM Analysis'] = llm_analysis\n",
    "            df.loc[idx, 'LLM score'] = llm_score\n",
    "\n",
    "            llm_response_dict[idx] = {'prompt': prompt, \n",
    "                                      'responses': analysis,\n",
    "                                      'finger_print': finger_print,\n",
    "                                      'status': 'SUCCESS'}\n",
    "        else:\n",
    "            print(f'No analysis for {idx}')\n",
    "            df.loc[idx, 'LLM Name'] = None\n",
    "            df.loc[idx, 'LLM Analysis'] = None\n",
    "            df.loc[idx, 'LLM Score'] = None\n",
    "            llm_response_dict[idx] = {'prompt': prompt,\n",
    "                                      'responses': None,\n",
    "                                      'finger_print': None,\n",
    "                                      'status': 'NO RESPONSE'}\n",
    "        i += 1\n",
    "    except Exception as e:\n",
    "        print(f'Error for {idx}: {e}')\n",
    "        df.loc[idx, 'LLM Name'] = None\n",
    "        df.loc[idx, 'LLM Analysis'] = None\n",
    "        llm_response_dict[idx] = {'prompt': prompt,\n",
    "                                    'responses': None,\n",
    "                                    'status': 'ERROR: '+str(e)}\n",
    "        continue\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        with open(f'{out_file}.json', 'w') as fp:\n",
    "            json.dump(llm_response_dict, fp)\n",
    "        df.to_csv(f'{out_file}.tsv', sep='\\t', index=True)\n",
    "\n",
    "with open(f'{out_file}.json', 'w') as fp:\n",
    "    json.dump(llm_response_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(genes, model):\n",
    "    prompt = make_user_prompt_with_score(genes)\n",
    "    # print(prompt)\n",
    "    if model.startwith('gpt'):\n",
    "        analysis = openai_chat(context, prompt, model, temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT)\n",
    "    \n",
    "    if analysis:\n",
    "        llm_process = analysis.split(\"\\n\")[0].replace(\"Process: \", \"\")\n",
    "        llm_score = llm_process.split(\" \")[-1].strip(\"()\")\n",
    "        llm_name = llm_process.rsplit(\" \", 1)[0]\n",
    "        llm_analysis = analysis.split('\\n', 2)[2]\n",
    "    else:\n",
    "        llm_name = None\n",
    "        llm_score = None\n",
    "        llm_analysis = None\n",
    "        \n",
    "    return llm_name, llm_score, llm_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genes</th>\n",
       "      <th>Gene_Count</th>\n",
       "      <th>Term_Description</th>\n",
       "      <th>50perc_contaminated_Genes</th>\n",
       "      <th>100perc_contaminated_Genes</th>\n",
       "      <th>LLM Name</th>\n",
       "      <th>LLM Analysis</th>\n",
       "      <th>LLM Score</th>\n",
       "      <th>50perc_contaminated_LLM Name</th>\n",
       "      <th>50perc_contaminated_LLM Analysis</th>\n",
       "      <th>50perc_contaminated_LLM Score</th>\n",
       "      <th>100perc_contaminated_LLM Name</th>\n",
       "      <th>100perc_contaminated_LLM Analysis</th>\n",
       "      <th>100perc_contaminated_LLM Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GO:0032385</th>\n",
       "      <td>LDLRAP1 SCP2D1 ANXA2 SCP2</td>\n",
       "      <td>4</td>\n",
       "      <td>positive regulation of intracellular cholester...</td>\n",
       "      <td>LDLRAP1 SCP2 TRIM45 NME5</td>\n",
       "      <td>HMGA2 MID2 HSFX2 FOXP4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0002468</th>\n",
       "      <td>NOD1 HLA-DRA CLEC4A HLA-DRB1 CCL21 NOD2 CCL19 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>dendritic cell antigen processing and presenta...</td>\n",
       "      <td>CD68 HLA-DRB3 CCL19 CCL21 HLA-DRA NOD2 THBS1 T...</td>\n",
       "      <td>JAG1 LTK ARL17A SLCO4A1 PLEKHO2 NDUFS5 ZC3H12D...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0033683</th>\n",
       "      <td>OGG1 ERCC5 XPA ERCC4 NTHL1</td>\n",
       "      <td>5</td>\n",
       "      <td>nucleotide-excision repair, DNA incision</td>\n",
       "      <td>XPA NTHL1 NAA11 SCD5 CDCA8</td>\n",
       "      <td>MBTPS2 PRCD BUB3 SLC13A1 FADS2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0035672</th>\n",
       "      <td>SLC7A11 SLC25A39 SLC26A6 ABCB9 SLC15A4 ABCC5 C...</td>\n",
       "      <td>15</td>\n",
       "      <td>oligopeptide transmembrane transport</td>\n",
       "      <td>GJA1 SLC15A4 SLC15A1 CDH17 SLC25A39 SLC26A6 SL...</td>\n",
       "      <td>DEFB113 GLMN CELA2B SIGLEC7 RIGI CCL3L3 DEFB11...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0048023</th>\n",
       "      <td>OPN3 CDH3 ATP7A APPL1 ASIP RAB38 ZEB2 TYRP1 GIPC1</td>\n",
       "      <td>9</td>\n",
       "      <td>positive regulation of melanin biosynthetic pr...</td>\n",
       "      <td>TYRP1 CDH3 OPN3 RAB38 FGFRL1 ZNF429 DUS3L CTSK...</td>\n",
       "      <td>WEE2 STIM1 EXOC4 MYO15A GLIPR1L1 ATAD3A CDCA5 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Genes  Gene_Count  \\\n",
       "GO                                                                          \n",
       "GO:0032385                          LDLRAP1 SCP2D1 ANXA2 SCP2           4   \n",
       "GO:0002468  NOD1 HLA-DRA CLEC4A HLA-DRB1 CCL21 NOD2 CCL19 ...          15   \n",
       "GO:0033683                         OGG1 ERCC5 XPA ERCC4 NTHL1           5   \n",
       "GO:0035672  SLC7A11 SLC25A39 SLC26A6 ABCB9 SLC15A4 ABCC5 C...          15   \n",
       "GO:0048023  OPN3 CDH3 ATP7A APPL1 ASIP RAB38 ZEB2 TYRP1 GIPC1           9   \n",
       "\n",
       "                                             Term_Description  \\\n",
       "GO                                                              \n",
       "GO:0032385  positive regulation of intracellular cholester...   \n",
       "GO:0002468  dendritic cell antigen processing and presenta...   \n",
       "GO:0033683           nucleotide-excision repair, DNA incision   \n",
       "GO:0035672               oligopeptide transmembrane transport   \n",
       "GO:0048023  positive regulation of melanin biosynthetic pr...   \n",
       "\n",
       "                                    50perc_contaminated_Genes  \\\n",
       "GO                                                              \n",
       "GO:0032385                           LDLRAP1 SCP2 TRIM45 NME5   \n",
       "GO:0002468  CD68 HLA-DRB3 CCL19 CCL21 HLA-DRA NOD2 THBS1 T...   \n",
       "GO:0033683                         XPA NTHL1 NAA11 SCD5 CDCA8   \n",
       "GO:0035672  GJA1 SLC15A4 SLC15A1 CDH17 SLC25A39 SLC26A6 SL...   \n",
       "GO:0048023  TYRP1 CDH3 OPN3 RAB38 FGFRL1 ZNF429 DUS3L CTSK...   \n",
       "\n",
       "                                   100perc_contaminated_Genes LLM Name  \\\n",
       "GO                                                                       \n",
       "GO:0032385                             HMGA2 MID2 HSFX2 FOXP4     None   \n",
       "GO:0002468  JAG1 LTK ARL17A SLCO4A1 PLEKHO2 NDUFS5 ZC3H12D...     None   \n",
       "GO:0033683                     MBTPS2 PRCD BUB3 SLC13A1 FADS2     None   \n",
       "GO:0035672  DEFB113 GLMN CELA2B SIGLEC7 RIGI CCL3L3 DEFB11...     None   \n",
       "GO:0048023  WEE2 STIM1 EXOC4 MYO15A GLIPR1L1 ATAD3A CDCA5 ...     None   \n",
       "\n",
       "           LLM Analysis LLM Score 50perc_contaminated_LLM Name  \\\n",
       "GO                                                               \n",
       "GO:0032385         None      None                         None   \n",
       "GO:0002468         None      None                         None   \n",
       "GO:0033683         None      None                         None   \n",
       "GO:0035672         None      None                         None   \n",
       "GO:0048023         None      None                         None   \n",
       "\n",
       "           50perc_contaminated_LLM Analysis 50perc_contaminated_LLM Score  \\\n",
       "GO                                                                          \n",
       "GO:0032385                             None                          None   \n",
       "GO:0002468                             None                          None   \n",
       "GO:0033683                             None                          None   \n",
       "GO:0035672                             None                          None   \n",
       "GO:0048023                             None                          None   \n",
       "\n",
       "           100perc_contaminated_LLM Name 100perc_contaminated_LLM Analysis  \\\n",
       "GO                                                                           \n",
       "GO:0032385                          None                              None   \n",
       "GO:0002468                          None                              None   \n",
       "GO:0033683                          None                              None   \n",
       "GO:0035672                          None                              None   \n",
       "GO:0048023                          None                              None   \n",
       "\n",
       "           100perc_contaminated_LLM Score  \n",
       "GO                                         \n",
       "GO:0032385                           None  \n",
       "GO:0002468                           None  \n",
       "GO:0033683                           None  \n",
       "GO:0035672                           None  \n",
       "GO:0048023                           None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new pipeline for running toy example and query for random and contaminated sets\n",
    "import pandas as pd\n",
    "import json \n",
    "from utils.openai_query import openai_chat\n",
    "from utils.prompt_factory import make_user_prompt_with_score\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "## check example_config.json for the format of the config file\n",
    "with open('./jsonFiles/GOLLMrun_config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "context = config['CONTEXT']\n",
    "gpt_model = config['GPT_MODEL']\n",
    "temperature = config['TEMP']\n",
    "max_tokens = config['MAX_TOKENS']\n",
    "rate_per_token = config['RATE_PER_TOKEN']\n",
    "LOG_FILE = config['LOG_NAME'] + '_log.json'\n",
    "DOLLAR_LIMIT = config['DOLLAR_LIMIT']\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"] # set your openai api key in the environment variable or set in config\n",
    "# Generate list of genes from file (file: data/go_terms_sample.csv) check notebook 0.[Prep GO] Download_and_parse_GO.ipynb\n",
    "df = pd.read_csv('data/GO_term_analysis/toy_example_contaminated.csv', sep = ',',index_col=0)\n",
    "\n",
    "columns = df.columns\n",
    "geneset_columns = columns[columns.str.endswith('Genes')]\n",
    "\n",
    "\n",
    "    \n",
    "df.head()\n",
    "# # print(df.head())\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    #initialize columns\n",
    "    for geneset in geneset_columns:\n",
    "        if 'contaminated' in geneset:\n",
    "            prefix = '_'.join(geneset.split('_')[:2])\n",
    "            \n",
    "            # initialize columns  \n",
    "            df[i, prefix + '_LLM Name'] = None\n",
    "            df[i, prefix + '_LLM Analysis'] = None\n",
    "            df[i, prefix + '_LLM Score'] = None\n",
    "        else:\n",
    "            df['LLM Name'] = None\n",
    "            df['LLM Analysis'] = None\n",
    "            df['LLM Score'] = None\n",
    "# for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "#     for geneset in df.columns.endswith('Genes'):\n",
    "#         if geneset.contains('contaminated'):\n",
    "#             prefix = '_'.join(geneset.split('_')[:1])\n",
    "#             # initialize columns  \n",
    "#             df[i, prefix + '_LLM Name'] = None\n",
    "#             df[i, prefix + '_LLM Analysis'] = None\n",
    "#             df[i, prefix + '_LLM Score'] = None\n",
    "#         else:\n",
    "#             df['LLM Name'] = None\n",
    "#             df['LLM Analysis'] = None\n",
    "#             df['LLM Score'] = None\n",
    "#         if col.endswith('contaminated_genes'):\n",
    "#             # Process each contaminated gene set\n",
    "#             contaminated_genes = row[col].split()\n",
    "#             prompt = make_user_prompt_with_score(contaminated_genes)\n",
    "            \n",
    "#             analysis = openai_chat(context, prompt, gpt_model, temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT)\n",
    "#             llm_process = analysis.split(\"\\n\")[0].replace(\"Process: \", \"\")\n",
    "#             llm_score = llm_process.split(\" \")[-1].strip(\"()\")\n",
    "#             llm_name = llm_process.rsplit(\" \", 1)[0]\n",
    "#             llm_analysis = analysis.split('\\n', 2)[2]\n",
    "            \n",
    "#             # Update DataFrame with results\n",
    "#             prefix = col.split('_')[0]\n",
    "#             df.loc[i, prefix + '_LLM Score'] = llm_score\n",
    "#             df.loc[i, prefix + '_LLM Name'] = llm_name\n",
    "#             df.loc[i, prefix + '_LLM Analysis'] = llm_analysis\n",
    "\n",
    "# # df.to_csv('data/GO_term_analysis/LLM_processed_toy_example_with_score.tsv', index=True, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the script for batch run\n",
    "\n",
    "input_file = 'data/GO_term_analysis/toy_example.csv'\n",
    "config = './jsonFiles/GOLLMrun_config.json'\n",
    "%run query_llm_for_analysis.py --input $input_file --start 0 --end 1 --config $config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkout and combine the output from the batch run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "### sanity check code along the way\n",
    "processed_files = glob('data/GO_term_analysis/LLM_processed_selected_go_terms*.tsv')\n",
    "\n",
    "for file in processed_files:\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    df.set_index('GO', inplace=True)\n",
    "    ranges = file.split('/')[-1].split('.')[0].split('_')[5:7]\n",
    "    with open(f'data/GO_term_analysis/LLM_response_go_terms_{ranges[0]}_{ranges[1]}.json') as fp:\n",
    "        llm_response_dict = json.load(fp)\n",
    "    for go_term, row in df.iterrows():\n",
    "        if llm_response_dict[go_term] == 'NO ANALYSIS':\n",
    "            print(file.split('/')[-1])\n",
    "            print(f'No analysis for {go_term}')\n",
    "            continue\n",
    "        else:\n",
    "            llm_analysis = llm_response_dict[go_term].split('\\n', 2)[2]\n",
    "            if df.loc[go_term, 'LLM Analysis'] != llm_analysis:\n",
    "                print(f'LLM analysis for {go_term} is different')\n",
    "            \n",
    "    df.reset_index(inplace=True)\n",
    "#     # print(ranges)\n",
    "    print(df.shape)\n",
    "\n",
    "    \n",
    "combined_df = pd.concat([pd.read_csv(f, sep = '\\t') for f in processed_files])\n",
    "print(combined_df.shape)\n",
    "print('Any duplicated GO: ',combined_df['GO'].duplicated().sum())\n",
    "print('Any NAs in the LLM res: ', combined_df['LLM Name'].isna().sum())\n",
    "print('Any duplicated LLM analysis: ', combined_df['LLM Analysis'].duplicated(keep=False).sum())\n",
    "\n",
    "combined_df.to_csv('data/GO_term_analysis/LLM_processed_selected_1000_go_terms.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
