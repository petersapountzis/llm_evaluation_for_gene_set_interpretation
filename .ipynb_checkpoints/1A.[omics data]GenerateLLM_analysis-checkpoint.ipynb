{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook queries GPT-4 and formats its response to obtain a succint name for each of the 'omics gene sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json \n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openai_query import openai_chat\n",
    "from utils.prompt_factory import make_user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"] # Environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Edit between runs\n",
    "dataType = \"NeST\"\n",
    "runVersion = \"test\" # \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataType == \"NeST\":\n",
    "    geneSep  = ',' # It is different with different sources of data\n",
    "    if runVersion == \"test\":\n",
    "        inputFilePath = \"data/NeST_table_subset.txt\"\n",
    "    else:\n",
    "        inputFilePath = \"data/NeST_table.txt\"\n",
    "    jsonFilePath = 'jsonFiles/NeSTRunLLM.json'\n",
    "    genesCol = 'Genes'\n",
    "    nameCol = 'NeST ID'\n",
    "    if runVersion == \"test\":\n",
    "        outputFilePath = 'data/NeST_table_subset_LLM_DF.tsv'\n",
    "    else:\n",
    "        outputFilePath = 'data/NeST_table_LLM_DF.tsv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonFilePath) as json_file:\n",
    "    config = json.load(json_file)\n",
    "    \n",
    "context = config['CONTEXT']\n",
    "gpt_model = config['GPT_MODEL']\n",
    "temperature = config['TEMP']\n",
    "max_tokens = config['MAX_TOKENS']\n",
    "rate_per_token = config['RATE_PER_TOKEN']\n",
    "LOG_FILE = config['LOG_NAME'] + 'log.json'\n",
    "DOLLAR_LIMIT = config['DOLLAR_LIMIT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GPT-4 query pipeline for NeST gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n",
      "585\n",
      "716\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(inputFilePath, sep = \"\\t\"); \n",
    "\n",
    "df['LLM Name'] = None\n",
    "df['LLM Analysis'] = None\n",
    "# print(df.head())\n",
    "\n",
    "#df.iloc.iterrows():\n",
    "for i, row in df.iterrows():\n",
    "    term_genes = row[genesCol]\n",
    "    genes = term_genes.split(geneSep) \n",
    "    prompt = make_user_prompt(genes)\n",
    "    \n",
    "    # print(prompt)\n",
    "    analysis = openai_chat(context, prompt, gpt_model,temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT)\n",
    "    if analysis:\n",
    "        llm_name = analysis.split(\"\\n\")[0].replace(\"Process: \", \"\")\n",
    "        df.loc[i, 'LLM Name'] = llm_name\n",
    "        \n",
    "        llm_analysis = analysis.split('\\n', 2)[2]\n",
    "        df.loc[i, 'LLM Analysis'] = llm_analysis\n",
    "    else:\n",
    "        #go_term = row['GO']\n",
    "        name = row[nameCol]\n",
    "        print(f'No analysis for {name}')\n",
    "        df.loc[i, 'LLM Name'] = None\n",
    "        df.loc[i, 'LLM Analysis'] = None\n",
    "    # print(go_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(outputFilePath, sep= '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run GPT-4 query pipeline for MSigDB gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "import openai\n",
    "from utils.openai_query import openai_chat\n",
    "from utils.prompt_factory import make_user_prompt\n",
    "## from here is loading yaml file\n",
    "import yaml \n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('jsonFiles/MSigDBRunLLM.json') as json_file:\n",
    "    config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = config['CONTEXT']\n",
    "gpt_model = config['GPT_MODEL']\n",
    "temperature = config['TEMP']\n",
    "max_tokens = config['MAX_TOKENS']\n",
    "rate_per_token = config['RATE_PER_TOKEN']\n",
    "LOG_FILE = config['LOG_NAME'] + 'log.json'\n",
    "DOLLAR_LIMIT = config['DOLLAR_LIMIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runVersion == \"test\":\n",
    "    filePaths = 'data/human_geneSets_subset//*.yaml'\n",
    "else: \n",
    "    filePaths = 'data/human_geneSets/*.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_files = glob(filePaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yaml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Remove .yaml files with no gene symbols\n",
    "yaml_files_to_remove = []\n",
    "\n",
    "for i, yaml_file in enumerate(yaml_files):\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    if 'gene_symbols' not in data:\n",
    "        yaml_files_to_remove.append(yaml_file) \n",
    "    elif len(data['gene_symbols']) ==0:\n",
    "        yaml_files_to_remove.append(yaml_file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[yaml_files.remove(yaml_file_to_remove) for yaml_file_to_remove in yaml_files_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yaml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runVersion == \"test\":\n",
    "    outputFile =  'data/MSigDB_table_subset_LLM_DF.tsv'\n",
    "else:\n",
    "    outputFile = 'data/MSigDB_table_LLM_DF.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runVersion ==  \"initial\" or runVersion == \"test\":\n",
    "    df = pd.DataFrame(columns=['Name', 'Genes', 'LLM Name', 'LLM Analysis'])\n",
    "else:\n",
    "    # It was run before -- read in dataframe\n",
    "\n",
    "    df = pd.read_csv(outputFile, sep = \"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1536\n",
      "1\n",
      "1123\n",
      "2\n",
      "1533\n"
     ]
    }
   ],
   "source": [
    "for i, yaml_file in enumerate(yaml_files):\n",
    "    print(i)\n",
    "    # Load your YAML file\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "        \n",
    "    if  (runVersion == \"additional\") and (df.loc[i, 'LLM Name'] is not None):\n",
    "        continue # move on to next item; it was already run \n",
    "        \n",
    "    # Get the list of genes from yaml\n",
    "    genes = data['gene_symbols']\n",
    "\n",
    "    #add to dataframe\n",
    "    df.loc[i, ['Name', 'Genes']] = [data['name'],(' ').join(genes)]\n",
    "    \n",
    "    prompt = make_user_prompt(genes)\n",
    "    # print(prompt)\n",
    "    analysis = openai_chat(context, prompt, gpt_model,temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT)\n",
    "    # print(analysis)\n",
    "    \n",
    "    \n",
    "    if analysis:\n",
    "        llm_name = analysis.split(\"\\n\")[0].replace(\"Process: \", \"\")\n",
    "        df.loc[i, 'LLM Name'] = llm_name\n",
    "        \n",
    "        llm_analysis = analysis.split('\\n', 2)[2]\n",
    "        df.loc[i, 'LLM Analysis'] = llm_analysis\n",
    "    else:\n",
    "        name = data['name']\n",
    "        print(f'No analysis for {name}')\n",
    "        df.loc[i, 'LLM Name'] = None\n",
    "        \n",
    "    # Keep on saving to not loose data if something happens\n",
    "    if (i%10 == 1):\n",
    "        df.to_csv(outputFile, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(outputFile, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/MSigDB_table_subset_LLM_DF.tsv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_go_evaluation",
   "language": "python",
   "name": "llm_go_evaluation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
